{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Log Classification\n",
    "\n",
    "This notebook adapts the Scikit Learn Log Classification notebook for Pytorch by building a neural network.\n",
    "\n",
    "We still use Scikit Learn for some functions, like labelling data and providing metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data(src_file_path, dst_file_path):\n",
    "    if not os.path.exists(dst_file_path):\n",
    "        os.mkdir(dst_file_path)\n",
    "    for logfile in glob.glob(src_file_path + \"/*.log\"):\n",
    "        if os.stat(logfile)[6] > 10000:\n",
    "            logfile_name = logfile.split('/')[-1]\n",
    "            shutil.copyfile(logfile, dst_file_path + \"/\" + logfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(logfile_path):\n",
    "    log_collection = pd.DataFrame()\n",
    "    logs = pd.DataFrame()\n",
    "    logfiles = glob.glob(logfile_path + \"/*.log\") # Get list of log files\n",
    "    for logfile in logfiles:\n",
    "        logs = pd.read_csv(logfile, sep=\"\\n\", header=None, names=['data'])\n",
    "        logs['type'] = logfile.split('/')[-1]\n",
    "        # Add log file data and type to log collection\n",
    "        log_collection = log_collection.append(logs)\n",
    "\n",
    "    # Remove empty lines\n",
    "    log_collection = log_collection.dropna()\n",
    "    # Reset the index\n",
    "    log_collection = log_collection.reset_index(drop=True)\n",
    "    \n",
    "    return log_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(text, labels):\n",
    "    tfidf_transformer = TfidfVectorizer()\n",
    "    X = tfidf_transformer.fit_transform(text).toarray()\n",
    "        \n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(labels)\n",
    "    y = encoder.transform(labels)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X_train, y_train, i, batch_size):\n",
    "    data = X_train[(i*batch_size):((i*batch_size)+batch_size)]\n",
    "    labels = y_train[(i*batch_size):((i*batch_size)+batch_size)]\n",
    "     \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, num_epochs, batch_size):\n",
    "    for epoch in tqdm_notebook(range(num_epochs)):\n",
    "        total_batches = int(len(X_train) / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in tqdm_notebook(range(total_batches)):\n",
    "            X_batch, y_batch = get_batch(X_train, y_train, i, batch_size)\n",
    "            data = Variable(torch.FloatTensor(X_batch))\n",
    "            labels = Variable(torch.LongTensor(y_batch))\n",
    "            labels = torch.max(labels, 1)[1]\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            outputs = network(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "        print ('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(actual, predictions):\n",
    "    print(\"\\033[1m Performance Report \\033[0m\\033[50m\\n\")\n",
    "    \n",
    "    actual = np.array(actual)\n",
    "    \n",
    "    print(confusion_matrix(actual, predictions))\n",
    "    print\n",
    "    print(classification_report(actual, predictions))\n",
    "    print(\"Accuracy: \" + str(round(accuracy_score(actual, predictions),2)))\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, dropout):\n",
    "        super(NN, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_dir = \"/var/log\"\n",
    "data_dir = \"data\"\n",
    "\n",
    "copy_data(source_data_dir, data_dir)\n",
    "log_collection = read_data(data_dir)\n",
    "\n",
    "X, y = prepare_data(log_collection['data'], log_collection['type'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = X_train.shape[1] # this is the vocab size\n",
    "hidden_size = 512\n",
    "num_classes = y_train.shape[1] \n",
    "dropout = 0.3\n",
    "\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NN(input_size, hidden_size, num_classes, dropout)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051e60029e4840499b0ad0ff3b5bb787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36448be6ac2427fac537730062dfbea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2199), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/tmp/log-analysis-test/test/lib/python2.7/site-packages/ipykernel_launcher.py:17: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ed87f75bbe4db2a72eeb6f8aa932eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2199), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 0.0143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec242e4e2fe4562a120cfc7e302ff01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2199), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.0228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1821bce9680a4001b1c2b5486c0785cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2199), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.0248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20dbe6252aef4e238d25e533c698c0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2199), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.0236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(X_train, y_train, num_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test labels\n",
    "test_inputs = Variable(torch.from_numpy(X_test).float())\n",
    "predicted = network.forward(test_inputs)\n",
    "predicted_classes = [ np.argmax(p) for p in predicted.detach().numpy() ]\n",
    "\n",
    "file_types = np.unique(log_collection['type'])\n",
    "predicted_labels = [ file_types[p] for p in predicted_classes]\n",
    "actual_labels = [ file_types[np.argmax(y)] for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Performance Report \u001b[0m\u001b[50m\n",
      "\n",
      "[[5872    0    0    0    0    0    0]\n",
      " [   0  327    0    0    0    0    0]\n",
      " [   0    0   46    0    0    0    0]\n",
      " [   0    0    0 3493   29    0    0]\n",
      " [   0    0    0  203 2712    0    0]\n",
      " [   0    0    0    0    0  926    1]\n",
      " [   0    0    0    0    0    4 3981]]\n",
      "\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                 corecaptured.log       1.00      1.00      1.00      5872\n",
      "                    fsck_apfs.log       1.00      1.00      1.00       327\n",
      "                     fsck_hfs.log       1.00      1.00      1.00        46\n",
      "                      install.log       0.95      0.99      0.97      3522\n",
      "                       system.log       0.99      0.93      0.96      2915\n",
      "wifi-11-07-2018__13:38:02.923.log       1.00      1.00      1.00       927\n",
      "                         wifi.log       1.00      1.00      1.00      3985\n",
      "\n",
      "                        micro avg       0.99      0.99      0.99     17594\n",
      "                        macro avg       0.99      0.99      0.99     17594\n",
      "                     weighted avg       0.99      0.99      0.99     17594\n",
      "\n",
      "Accuracy: 0.99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report\n",
    "report(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
